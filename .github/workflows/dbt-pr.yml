name: Run dbt in test environment, run unit tests, check SQL formatting

on:
  workflow_call:
    inputs:
      dbt_path:
        description: Path to folder with dbt project (without trailing slash)
        type: string
        required: true
      dbt_args:
        description: Extra arguments to dbt, typically --target and --profile
        type: string
        required: true
      dbt_project_name:
        description: Name of the dbt project, used to select only models from this project for dbt run/test
        type: string
        required: true
      stm_project_id:
        description: ID of STM project on Google cloud
        type: string
        required: true
      stm_docs_bucket:
        description: Name of docs bucket in STM (without gs://)
        type: string
        required: true
      atm_docs_bucket:
        description: Name of docs bucket in ATM (without gs://)
        type: string
        required: true
      projects_config_path:
        description: Path to folder with projects.config.json
        type: string
        required: true
      service_account:
        description: Name of service account to run dbt with (default project-service-account)
        type: string
        required: false
        default: project-service-account

env:
  DBT_DATASET: pr_${{ github.event.pull_request.number }}_${{ github.run_number }}_${{ github.run_attempt }}

jobs:
  test:
    name: Run dbt unit tests, generate docs
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      id-token: write
    defaults:
      run:
        working-directory: ${{ inputs.dbt_path }}
    steps:
      - name: Check out
        uses: actions/checkout@master

      - name: Install python
        uses: actions/setup-python@v1
        with:
          python-version: "3.7.x"

      - name: Install dependencies
        run: pip install dbt-bigquery

      - name: Install dbt dependencies
        run: dbt deps ${{ inputs.dbt_args }}

      - name: Setup gcloud for STM
        uses: svvsaga/github-actions-public/setup-gcloud@v17.0.2
        with:
          environment: STM
          app_root: ${{ inputs.projects_config_path }}
          service_account: ${{ inputs.service_account }}

      - name: dbt compile
        run: dbt compile ${{ inputs.dbt_args }}

      - name: Run unit tests
        run: dbt test --select ${{ inputs.dbt_project_name }},tag:unit-test ${{ inputs.dbt_args }}

      - name: dbt seed
        run: dbt seed --select ${{ inputs.dbt_project_name }} ${{ inputs.dbt_args }}

      - name: dbt run
        run: dbt run --select ${{ inputs.dbt_project_name }} ${{ inputs.dbt_args }}

      - name: Generate docs
        run: dbt docs generate --exclude tag:unit-test ${{ inputs.dbt_args }}

      - name: Delete temporary datasets
        if: always()
        run: bq ls -d --project_id ${{ inputs.stm_project_id }} | grep "${{ env.DBT_DATASET }}" | xargs -n1 bq rm -r -f --project_id ${{ inputs.stm_project_id }} -d

      - name: Generate single HTML docs file
        uses: svvsaga/dbt-public/.github/actions/generate-single-doc-file@v1.0.2
        with:
          dbt-path: ${{ inputs.dbt_path }}

      - name: Copy HTML docs to Cloud Storage
        run: gsutil cp target/single_index.html gs://${{ inputs.stm_docs_bucket }}/pr/${{ env.DBT_DATASET }}.html

      - name: Setup gcloud for ATM
        uses: svvsaga/github-actions-public/setup-gcloud@v17.0.2
        with:
          environment: ATM
          app_root: ${{ inputs.projects_config_path }}
          service_account: ${{ inputs.service_account }}

      - id: copy-catalog
        name: Copy ATM catalog from Cloud Storage
        run: gsutil cp gs://${{ inputs.atm_docs_bucket }}/catalog.json .
        continue-on-error: true

      - name: Install json-diff
        if: steps.copy-catalog.outcome == 'success'
        run: npm install json-diff

      - name: Compare catalogs
        if: steps.copy-catalog.outcome == 'success'
        id: catalog_diff
        # Ignore changes in metadata and schema, since in our PR, all models are  materialized in the same schema
        run: |
          jq 'del(.metadata) | del(.nodes[].metadata.schema) | del(.nodes[].metadata.database) | del(.nodes[].stats) | del(.nodes[].metadata.type) | del(.sources[].stats) | del(.sources[].metadata.database)' catalog.json > catalog-modified.json
          jq 'del(.metadata) | del(.nodes[].metadata.schema) | del(.nodes[].metadata.database) | del(.nodes[].stats) | del(.nodes[].metadata.type) | del(.sources[].stats) | del(.sources[].metadata.database)' target/catalog.json > target/catalog-modified.json
          DIFF=$(npx json-diff catalog-modified.json target/catalog-modified.json | head -c 61000)
          if [[ ${#DIFF} -gt 60000 ]] ; then
              DIFF="${DIFF::60000}"$'\n...\nDiff too long to be shown in full'
          fi
          echo "diff<<EOF" >> $GITHUB_OUTPUT
          echo "$DIFF" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

  post-to-pr:
    name: Post catalog diff to PR
    runs-on: ubuntu-latest
    needs: test
    permissions:
      pull-requests: write
    steps:
      - name: Post catalog diff to PR
        uses: thollander/actions-comment-pull-request@632cf9ce90574d125be56b5f3405cda41a84e2fd
        with:
          message: |
            [dbt docs for this PR](https://storage.cloud.google.com/${{ inputs.stm_docs_bucket }}/pr/${{ env.DBT_DATASET }}.html?authuser=0)

            dbt schema changes introduced by this PR (compared to ATM, excluding dataset changes):
            ```diff
            ${{ needs.test.outputs.diff }}
            ```
          GITHUB_TOKEN: ${{ github.token }}
          comment_includes: 'dbt docs for this PR'